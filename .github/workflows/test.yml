name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run tests daily at 6 AM UTC
    - cron: '0 6 * * *'

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  # Backend Python Tests
  backend-tests:
    name: Backend Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    strategy:
      matrix:
        test-type: [unit, integration, security, performance]
        include:
          - test-type: unit
            markers: "unit and not slow"
            timeout: 15
          - test-type: integration
            markers: "integration"
            timeout: 25
          - test-type: security
            markers: "security"
            timeout: 20
          - test-type: performance
            markers: "performance"
            timeout: 30
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_baseball_trade_ai
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y postgresql-client

    - name: Install Python dependencies
      run: |
        cd backend
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt

    - name: Set up test environment
      run: |
        cd backend
        cp .env.test.example .env.test || echo "No test env template found"
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_baseball_trade_ai
        REDIS_URL: redis://localhost:6379/1
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST || 'test-key' }}
        SUPABASE_URL: ${{ secrets.SUPABASE_TEST_URL || 'http://test-supabase.com' }}
        SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_TEST_KEY || 'test-key' }}
        ENVIRONMENT: testing

    - name: Run ${{ matrix.test-type }} tests
      run: |
        cd backend
        pytest -m "${{ matrix.markers }}" \
          --timeout=${{ matrix.timeout * 60 }} \
          --cov-report=xml \
          --cov-report=term \
          --junit-xml=test-results-${{ matrix.test-type }}.xml \
          --html=test-report-${{ matrix.test-type }}.html \
          --self-contained-html
      timeout-minutes: ${{ matrix.timeout }}

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: backend-test-results-${{ matrix.test-type }}
        path: |
          backend/test-results-*.xml
          backend/test-report-*.html
          backend/coverage.xml
          backend/htmlcov/

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.test-type == 'unit'
      with:
        file: ./backend/coverage.xml
        flags: backend
        name: backend-coverage

  # Frontend Tests
  frontend-tests:
    name: Frontend Tests
    runs-on: ubuntu-latest
    timeout-minutes: 25

    strategy:
      matrix:
        test-type: [unit, integration]
        include:
          - test-type: unit
            command: "npm run test:unit"
          - test-type: integration
            command: "npm run test:integration"

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install dependencies
      run: |
        cd frontend
        npm ci

    - name: Run ${{ matrix.test-type }} tests
      run: |
        cd frontend
        ${{ matrix.command }}

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: frontend-test-results-${{ matrix.test-type }}
        path: |
          frontend/coverage/
          frontend/test-results/

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.test-type == 'unit'
      with:
        file: ./frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage

  # E2E Tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: [backend-tests, frontend-tests]

    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
      fail-fast: false

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install frontend dependencies
      run: |
        cd frontend
        npm ci

    - name: Install backend dependencies
      run: |
        cd backend
        pip install -r requirements.txt

    - name: Install Playwright
      run: |
        cd frontend
        npx playwright install --with-deps ${{ matrix.browser }}

    - name: Build frontend
      run: |
        cd frontend
        npm run build

    - name: Run E2E tests
      run: |
        cd frontend
        npx playwright test --project=${{ matrix.browser }}
      env:
        PLAYWRIGHT_BASE_URL: http://localhost:3000
        NEXT_PUBLIC_API_URL: http://localhost:8000

    - name: Upload E2E test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-results-${{ matrix.browser }}
        path: |
          frontend/playwright-report/
          frontend/test-results/

  # Code Quality Checks
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install Python dependencies
      run: |
        cd backend
        pip install -r requirements-test.txt

    - name: Install Node dependencies
      run: |
        cd frontend
        npm ci

    - name: Python code formatting (Black)
      run: |
        cd backend
        black --check --diff .

    - name: Python import sorting (isort)
      run: |
        cd backend
        isort --check-only --diff .

    - name: Python linting (flake8)
      run: |
        cd backend
        flake8 .

    - name: Python type checking (mypy)
      run: |
        cd backend
        mypy . || true  # Don't fail on type errors yet

    - name: Python security check (bandit)
      run: |
        cd backend
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . || true

    - name: TypeScript type checking
      run: |
        cd frontend
        npm run type-check

    - name: Frontend linting (ESLint)
      run: |
        cd frontend
        npm run lint

    - name: Frontend formatting (Prettier)
      run: |
        cd frontend
        npm run format:check

    - name: Upload code quality reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: code-quality-reports
        path: |
          backend/bandit-report.json

  # Security Scanning
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

    - name: Python dependency check
      run: |
        cd backend
        pip install safety
        safety check --json --output safety-report.json || true
        safety check || true

    - name: Node.js audit
      run: |
        cd frontend
        npm audit --audit-level=moderate || true

  # Test Summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests, e2e-tests, code-quality, security-scan]
    if: always()

    steps:
    - name: Download all test artifacts
      uses: actions/download-artifact@v3

    - name: Generate test summary
      run: |
        echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Count test files
        BACKEND_UNIT_RESULTS=$(find . -name "*unit*.xml" | wc -l)
        BACKEND_INTEGRATION_RESULTS=$(find . -name "*integration*.xml" | wc -l)
        BACKEND_SECURITY_RESULTS=$(find . -name "*security*.xml" | wc -l)
        BACKEND_PERFORMANCE_RESULTS=$(find . -name "*performance*.xml" | wc -l)
        
        echo "### Backend Tests" >> $GITHUB_STEP_SUMMARY
        echo "- Unit Tests: $BACKEND_UNIT_RESULTS files" >> $GITHUB_STEP_SUMMARY
        echo "- Integration Tests: $BACKEND_INTEGRATION_RESULTS files" >> $GITHUB_STEP_SUMMARY
        echo "- Security Tests: $BACKEND_SECURITY_RESULTS files" >> $GITHUB_STEP_SUMMARY
        echo "- Performance Tests: $BACKEND_PERFORMANCE_RESULTS files" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # E2E results
        E2E_RESULTS=$(find . -name "playwright-report" -type d | wc -l)
        echo "### E2E Tests" >> $GITHUB_STEP_SUMMARY
        echo "- Browser Tests: $E2E_RESULTS browsers" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "### Job Status" >> $GITHUB_STEP_SUMMARY
        echo "- Backend Tests: ${{ needs.backend-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Frontend Tests: ${{ needs.frontend-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- E2E Tests: ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Code Quality: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Security Scan: ${{ needs.security-scan.result }}" >> $GITHUB_STEP_SUMMARY

# Workflow dispatch for manual runs
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Test type to run'
        required: false
        default: 'all'
        type: choice
        options:
        - all
        - backend-only
        - frontend-only
        - e2e-only
        - security-only
      
      browser:
        description: 'Browser for E2E tests'
        required: false
        default: 'chromium'
        type: choice
        options:
        - chromium
        - firefox
        - webkit
        - all